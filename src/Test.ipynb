{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;font-size:30px;\" > Testing For Damage Prediction Modeling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.1 Enable interactive widget in jupyter</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2 Fucntion to read variable details for prediction</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readType():\n",
    "\n",
    "    with open('../variable-details/dataTypes.json', 'r') as f:\n",
    "        data_types = json.load(f)\n",
    "        \n",
    "    with open('../variable-details/TrainDataTypes.json', 'r') as f:\n",
    "        train_data_types = json.load(f)\n",
    "        \n",
    "    data_types.pop('Row_ID')\n",
    "    data_types.pop('Household_ID')\n",
    "    data_types.pop('Claim_Amount')\n",
    "\n",
    "    same_col = []\n",
    "    cols4dummies = ['Cat1', 'Cat2', 'Cat3', 'Cat4', 'Cat5', 'Cat6', 'Cat7', 'Cat8', 'Cat9', 'Cat10', 'Cat11', 'Cat12', 'OrdCat', 'NVCat']\n",
    "    for i in data_types.keys():#list(data_types.keys())[0:5] + list(data_types.keys())[18:31]\n",
    "        if i not in cols4dummies:\n",
    "            same_col.append(i)\n",
    "    return data_types, train_data_types, same_col\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3 Fucntion to Load trained Model for Prediction</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loadModel():\n",
    "    # load the model from disk\n",
    "    loaded_model = pickle.load(open('../saved-model/RandomForestModel.sav', 'rb'))\n",
    "    return loaded_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4 Fucntion to Load Category Encoders saved as .pkl file</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoderLoad():\n",
    "    pickleLoaded = dict()\n",
    "    for col in ['Blind_Make','Blind_Model','Blind_Submodel']:\n",
    "        pkl_file = open('../encoder-files/'+col+'.pkl', 'rb')\n",
    "        pick = pickle.load(pkl_file) \n",
    "        pickleLoaded[col] = pick\n",
    "        pkl_file.close()\n",
    "    return pickleLoaded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>5 Function to Predict for a input data</h1>\n",
    "<p>The function takes the 32 variables as inputs and then trasforms and ecnodes for prediction. The categoroial variables gets encodes and the object variable gets converted into one hot</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_inpt, data_types, train_data_types, same_col):\n",
    "\n",
    "    pickleLoaded = encoderLoad()\n",
    "    loaded_model = loadModel()\n",
    "    colm = list(train_data_types.keys())\n",
    "    mod_inputs = pd.DataFrame(columns=colm)\n",
    "    mod_inputs = mod_inputs.astype(train_data_types) \n",
    "    data = []\n",
    "    \n",
    "    for col in colm:\n",
    "        if col in same_col:\n",
    "            \n",
    "            if col in ['Blind_Make','Blind_Model','Blind_Submodel']:\n",
    "                le = pickleLoaded[col]\n",
    "                test_inpt[col] = le.transform(test_inpt[col])\n",
    "                data.append(test_inpt.loc[0,col])\n",
    "            else:\n",
    "                data.append(test_inpt.loc[0,col])\n",
    "        else:\n",
    "            data.append(0)\n",
    "\n",
    "    s2 = pd.Series(data, index=list(train_data_types.keys()))\n",
    "    mod_inputs = mod_inputs.append(s2,ignore_index=True)\n",
    "    dummy_col = ['Cat1', 'Cat2', 'Cat3', 'Cat4', 'Cat5', 'Cat6', 'Cat7', 'Cat8', 'Cat9', 'Cat10', 'Cat11', 'Cat12', 'OrdCat', 'NVCat']\n",
    "    for col in dummy_col:\n",
    "        val = test_inpt.loc[0,col]\n",
    "        val = col+\"_\"+val\n",
    "        \n",
    "        if val in list(mod_inputs.columns):\n",
    "            \n",
    "            mod_inputs.loc[0,val]=1\n",
    "        #else:\n",
    "        #    print(val)\n",
    "        #print(val)\n",
    "        #print(mod_inputs.shape)\n",
    "    result = loaded_model.predict([mod_inputs.iloc[0,:]])\n",
    "    return result[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>6 Function to get a pandas dataframe of test inputs</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testInput(data, data_types):\n",
    "    test_inpt = pd.DataFrame(columns=data_types.keys())\n",
    "    test_inpt = test_inpt.astype(data_types) \n",
    "\n",
    "    s2 = pd.Series(data, index=list(data_types.keys()))\n",
    "    test_inpt = test_inpt.append(s2,ignore_index=True)\n",
    "    return test_inpt\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>7 The Raw data frame is loaded to populate drop down data for interactive buttons for testing data</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 100000\n",
      "Number of data features: 35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_types, train_data_types, same_col = readType()\n",
    "\n",
    "df = pd.read_csv(\"../raw-data/podatki.csv\")\n",
    "\n",
    "print(\"Number of data points:\",df.shape[0])\n",
    "print(\"Number of data features:\",df.shape[1])\n",
    "df.drop(['Row_ID','Household_ID','Claim_Amount'], axis=1, inplace=True)\n",
    "\n",
    "# data = []\n",
    "# for i in range(len(data_types.keys())):\n",
    "#     data.append(df.iloc[10880,i])\n",
    "# test_inpt = testInput(data, data_types)\n",
    "\n",
    "# t = predict(test_inpt, data_types, train_data_types, same_col)\n",
    "# print(\"Predicted Result is\",t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>7 Test Using the below given interactive drop down module for prediction</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad14bf3810224078b62b593f7f268c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Vehicle', options=(4, 1, 3, 5, 2, 6, 8, 7, 9, 10, 12, 11, 14, 17, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def getResults(\n",
    " Vehicle=list(df['Vehicle'].unique()),\n",
    " Calendar_Year=list(df['Calendar_Year'].unique()),\n",
    " Model_Year=list(df['Model_Year'].unique()),\n",
    " Blind_Make=list(df['Blind_Make'].unique()),\n",
    " Blind_Model=list(df['Blind_Model'].unique()),\n",
    " Blind_Submodel=list(df['Blind_Submodel'].unique()),\n",
    " Cat1=list(df['Cat1'].unique()),\n",
    " Cat2=list(df['Cat2'].unique()),\n",
    " Cat3=list(df['Cat3'].unique()),\n",
    " Cat4=list(df['Cat4'].unique()),\n",
    " Cat5=list(df['Cat5'].unique()),\n",
    " Cat6=list(df['Cat6'].unique()),\n",
    " Cat7=list(df['Cat7'].unique()),\n",
    " Cat8=list(df['Cat8'].unique()),\n",
    " Cat9=list(df['Cat9'].unique()),\n",
    " Cat10=list(df['Cat10'].unique()),\n",
    " Cat11=list(df['Cat11'].unique()),\n",
    " Cat12=list(df['Cat12'].unique()),\n",
    " OrdCat=list(df['OrdCat'].unique()),\n",
    " Var1=widgets.FloatText(\n",
    "    value=0.5,\n",
    "    disabled=False\n",
    "),\n",
    " Var2=widgets.FloatText(\n",
    "    value=0.5,\n",
    "    disabled=False\n",
    "),\n",
    " Var3=widgets.FloatText(\n",
    "    value=0.5,\n",
    "    disabled=False\n",
    "),\n",
    " Var4=widgets.FloatText(\n",
    "    value=0.5,\n",
    "    disabled=False\n",
    "),\n",
    " Var5=widgets.FloatText(\n",
    "    value=0.5,\n",
    "    disabled=False\n",
    "),\n",
    " Var6=widgets.FloatText(\n",
    "    value=0.5,\n",
    "    disabled=False\n",
    "),\n",
    " Var7=widgets.FloatText(\n",
    "    value=0.5,\n",
    "    disabled=False\n",
    "),\n",
    " Var8=widgets.FloatText(\n",
    "    value=0.5,\n",
    "    disabled=False\n",
    "),\n",
    " NVCat=list(df['NVCat'].unique()),\n",
    " NVVar1=widgets.FloatText(\n",
    "    value=0.5,\n",
    "    disabled=False\n",
    "),\n",
    " NVVar2=widgets.FloatText(\n",
    "    value=0.5,\n",
    "    disabled=False\n",
    "),\n",
    " NVVar3=widgets.FloatText(\n",
    "    value=0.5,\n",
    "    disabled=False\n",
    "),\n",
    " NVVar4=\n",
    "widgets.FloatText(\n",
    "    value=7.5,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "):\n",
    "    data=[Vehicle,\n",
    " Calendar_Year,\n",
    " Model_Year,\n",
    " Blind_Make,\n",
    " Blind_Model,\n",
    " Blind_Submodel,\n",
    " Cat1,\n",
    " Cat2,\n",
    " Cat3,\n",
    " Cat4,\n",
    " Cat5,\n",
    " Cat6,\n",
    " Cat7,\n",
    " Cat8,\n",
    " Cat9,\n",
    " Cat10,\n",
    " Cat11,\n",
    " Cat12,\n",
    " OrdCat,\n",
    " Var1,\n",
    " Var2,\n",
    " Var3,\n",
    " Var4,\n",
    " Var5,\n",
    " Var6,\n",
    " Var7,\n",
    " Var8,\n",
    " NVCat,\n",
    " NVVar1,\n",
    " NVVar2,\n",
    " NVVar3,\n",
    " NVVar4]\n",
    "    test_inpt = testInput(data, data_types)\n",
    "\n",
    "    t = predict(test_inpt, data_types, train_data_types, same_col)\n",
    "    print(\"Predicted Damage Result is\",t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
